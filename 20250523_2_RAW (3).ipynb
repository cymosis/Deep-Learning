{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Deep Network Development Exam - Coding Section**\n",
        "\n",
        "---\n",
        "\n",
        "## **Student Information**\n",
        "- **Name:** <*Enter your full name*>\n",
        "- **Neptun ID:** <*Enter your Neptun ID*>\n",
        "- **Date:** 23/05/2025  \n",
        "- **Time Slot:** 09:00 - 09:30 (30 minutes)\n",
        "\n",
        "---\n",
        "\n",
        "## **Overview**\n",
        "\n",
        "This coding task must be completed to qualify for the second part of the final exam (1-hour written session). Final course grades will be assigned based on overall performance during the active semester, provided both components are passed.\n",
        "\n",
        "---\n",
        "\n",
        "## **Task Requirements**\n",
        "\n",
        "- Implement a **neural network architecture**, including a **functioning forward pass**.\n",
        "- The code must run without errors and meet the minimum implementation criteria.\n",
        "\n",
        "---\n",
        "\n",
        "## **Rules and Resources**\n",
        "\n",
        "| Allowed                            | Not Allowed                                  |\n",
        "|-----------------------------------|----------------------------------------------|\n",
        "| Internet access                   | Communication with others (e.g., Teams, WhatsApp, Messenger) |\n",
        "| AI tools (e.g., ChatGPT, Copilot) | Collaboration or assistance from peers       |\n",
        "| Practice notebooks                | Use of group chats, forums, or messaging apps|\n",
        "\n",
        "> Any violation will result in **immediate disqualification** and a **failing grade**.\n",
        "\n",
        "---\n",
        "\n",
        "## **Submission Guidelines**\n",
        "\n",
        "- Submit your solution as a **`.ipynb` file** on **Canvas**\n",
        "- Late submissions or incomplete solutions will not be accepted\n",
        "- Your code must be fully executable and meet the minimum task requirements\n",
        "\n",
        "---\n",
        "\n",
        "## **Retake Policy**\n",
        "\n",
        "- If this part is failed, **one retake opportunity** will be provided  \n",
        "- Failing the retake results in a **fail for the course**\n",
        "\n",
        "---\n",
        "\n",
        "**Good luck!**\n"
      ],
      "metadata": {
        "id": "DBpfD9z3SiMV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task Description**\n",
        "\n",
        "Your task is to implement a **custom neural network architecture**, including a fully functional `forward()` method.\n",
        "\n",
        "You will be provided with a **diagram of the model architecture**. Some components will contain a **`?` symbol**, indicating that you must determine and specify the appropriate hyperparameters or configurations based on the overall architecture and problem.\n",
        "\n",
        "Please note the following:\n",
        "- **All layers shown in the diagram must be included** in your implementation.\n",
        "- In some cases, **connections may not be fully drawn**, but this does not mean the layer is optional.\n",
        "- Only the **final output dimensions** are required to match exactly.\n",
        "- The implementation will be **manually reviewed**, so correctness of structure and logic is essential.\n"
      ],
      "metadata": {
        "id": "eeb5t4EiSld1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **0. Necessary Imports and Data Loading**"
      ],
      "metadata": {
        "id": "qFHVdn0GF95L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FAofci_7R6kB"
      },
      "outputs": [],
      "source": [
        "# Cell 0.1 (DO NOT EDIT THIS CELL!)\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import gdown\n",
        "import requests\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 0.2 (DO NOT EDIT THIS CELL!)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "WgOK-xATFdDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c90375da-9177-4deb-d025-c0d2e542ab89"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Architecture**\n",
        "\n",
        "To better view the architecture diagram:  \n",
        "- **Right-click the image** and select **\"Open image in a new tab\"** to enable zoom for a clearer view.  \n",
        "- Alternatively, you can **download the image** using the link below:  \n",
        "  [Download Architecture Diagram](https://drive.google.com/file/d/1JcBQtuTv9O6090VbCvupLo2qRfEYjyMY/view?usp=sharing)\n",
        "\n",
        "---\n",
        "\n",
        "### **Diagram Preview**:\n",
        "![Architecture Diagram](https://drive.google.com/uc?export=view&id=1JcBQtuTv9O6090VbCvupLo2qRfEYjyMY)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cV5xi065Fk1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.1 (EDIT THIS CELL!)\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.upper=nn.Sequential(nn.Conv2d(3,16,kernel_size=4, stride=3, padding=1),\n",
        "                                 nn.BatchNorm2d(16),\n",
        "                                 nn.MaxPool2d(2,2)\n",
        "                                 )\n",
        "        self.lower=nn.Sequential(nn.Conv2d(3,16,kernel_size=3, stride=2, padding=1),\n",
        "                                 nn.BatchNorm2d(16),\n",
        "                                 nn.MaxPool2d(kernel_size=3, stride=3)\n",
        "                                 )\n",
        "        self.cont=nn.Sequential(nn.Conv2d(48,32,kernel_size=5, stride=1, padding=2))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"[image] Input image shape: {x.shape}\")\n",
        "        x1=self.upper(x)\n",
        "        print(x1.shape)\n",
        "        x2=self.lower(x)\n",
        "        print(x2.shape)\n",
        "        x3=torch.randn(1,16,5,5).to(device)\n",
        "        print(x3.shape)\n",
        "        x4=torch.cat((x1,x2,x3),dim=1)\n",
        "        print(x4.shape)\n",
        "        x5=self.cont(x4)\n",
        "        print(x5.shape)\n",
        "        x6=nn.Sigmoid()(x5)\n",
        "        print(x6.shape)\n",
        "        x7=x6*x5\n",
        "        print(x7.shape)\n",
        "        x8=nn.Conv2d(32,16,kernel_size=5, stride=1, padding=2)(x7)\n",
        "        print(x8.shape)\n",
        "        x9=x8+x1\n",
        "        print('x9.shape')\n",
        "        print(x9.shape)\n",
        "        x_flat = x9.view(1, -1)  # or x.reshape(x.size(0), -1)\n",
        "\n",
        "        print(x_flat.shape)  # torch.Size([1, 400])\n",
        "        linear=nn.Linear(400,4096)(x_flat)\n",
        "        print(linear.shape)\n",
        "        x_seq = linear.view(1, 32, 128)  # [batch, seq_len, input_size]\n",
        "\n",
        "        lstm = nn.LSTM(input_size=128, hidden_size=128, num_layers=2, batch_first=True)\n",
        "        x_lstm, _ = lstm(x_seq)\n",
        "        print(x_lstm.shape)\n",
        "        x_lstm=x_lstm.view(1,-1)\n",
        "        x10=nn.Linear(4096,2048)(x_lstm)\n",
        "        print(x10.shape)\n",
        "        x10=x10.view(1,32,8,8)\n",
        "\n",
        "        x11=nn.ConvTranspose2d(32,32,kernel_size=3, stride=2, padding=1, output_padding=1)(x10)\n",
        "        print(x11.shape)\n",
        "        x12=x11.view(x11.size(0),x11.size(1),-1)\n",
        "        print(x12.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        return x12"
      ],
      "metadata": {
        "id": "hHJ70LQXMVQa"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1.2 (DO NOT EDIT THIS CELL!)\n",
        "\n",
        "custom_model = CustomModel().to(device)\n",
        "img = torch.randn(1, 3, 32, 32).to(device)\n",
        "\n",
        "output = custom_model(img)\n",
        "\n",
        "print(\"Output Shape:\", output.shape)\n",
        "\n",
        "try:\n",
        "    assert output.shape == (1, 32, 256), \"Output shape is incorrect.\"\n",
        "    print(\"\\nüéâ Congratulations! Your implementation is correct. You passed the first part of the exam! üéâ\")\n",
        "except AssertionError as e:\n",
        "    print(f\"\\n‚ùå Error: {e}\")"
      ],
      "metadata": {
        "id": "y6BWkKwEOgDh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23548998-7551-445c-e1a0-b6301e133291"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[image] Input image shape: torch.Size([1, 3, 32, 32])\n",
            "torch.Size([1, 16, 5, 5])\n",
            "torch.Size([1, 16, 5, 5])\n",
            "torch.Size([1, 16, 5, 5])\n",
            "torch.Size([1, 48, 5, 5])\n",
            "torch.Size([1, 32, 5, 5])\n",
            "torch.Size([1, 32, 5, 5])\n",
            "torch.Size([1, 32, 5, 5])\n",
            "torch.Size([1, 16, 5, 5])\n",
            "x9.shape\n",
            "torch.Size([1, 16, 5, 5])\n",
            "torch.Size([1, 400])\n",
            "torch.Size([1, 4096])\n",
            "torch.Size([1, 32, 128])\n",
            "torch.Size([1, 2048])\n",
            "torch.Size([1, 32, 16, 16])\n",
            "torch.Size([1, 32, 256])\n",
            "Output Shape: torch.Size([1, 32, 256])\n",
            "\n",
            "üéâ Congratulations! Your implementation is correct. You passed the first part of the exam! üéâ\n"
          ]
        }
      ]
    }
  ]
}